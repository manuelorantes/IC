{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolucionRelu_64_128_256_512.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY0p33JKroTh"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EElLKgKgxrb9",
        "outputId": "52ed35a8-2dcc-4121-e76c-96c89f1bd973"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGhZ7NwRxw52",
        "outputId": "8fbd6af0-3d4d-4a6e-fc1c-165023d51246"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(256, activation=\"relu\"),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                102464    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 299,338\n",
            "Trainable params: 299,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpaoiV70x4_N",
        "outputId": "38f97d7a-e5d9-4645-c811-d590ed973448"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 25\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "end = time.time()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "422/422 [==============================] - 42s 99ms/step - loss: 0.4313 - accuracy: 0.8552 - val_loss: 0.0616 - val_accuracy: 0.9810\n",
            "Epoch 2/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.1327 - accuracy: 0.9613 - val_loss: 0.0430 - val_accuracy: 0.9877\n",
            "Epoch 3/25\n",
            "422/422 [==============================] - 42s 99ms/step - loss: 0.0990 - accuracy: 0.9715 - val_loss: 0.0389 - val_accuracy: 0.9893\n",
            "Epoch 4/25\n",
            "422/422 [==============================] - 42s 98ms/step - loss: 0.0852 - accuracy: 0.9754 - val_loss: 0.0367 - val_accuracy: 0.9905\n",
            "Epoch 5/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.0765 - accuracy: 0.9784 - val_loss: 0.0393 - val_accuracy: 0.9888\n",
            "Epoch 6/25\n",
            "422/422 [==============================] - 42s 99ms/step - loss: 0.0657 - accuracy: 0.9812 - val_loss: 0.0303 - val_accuracy: 0.9922\n",
            "Epoch 7/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.0646 - accuracy: 0.9818 - val_loss: 0.0305 - val_accuracy: 0.9917\n",
            "Epoch 8/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.0582 - accuracy: 0.9834 - val_loss: 0.0288 - val_accuracy: 0.9927\n",
            "Epoch 9/25\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0571 - accuracy: 0.9837 - val_loss: 0.0299 - val_accuracy: 0.9918\n",
            "Epoch 10/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.0526 - accuracy: 0.9847 - val_loss: 0.0298 - val_accuracy: 0.9912\n",
            "Epoch 11/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.0528 - accuracy: 0.9858 - val_loss: 0.0280 - val_accuracy: 0.9925\n",
            "Epoch 12/25\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0486 - accuracy: 0.9861 - val_loss: 0.0280 - val_accuracy: 0.9930\n",
            "Epoch 13/25\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0466 - accuracy: 0.9870 - val_loss: 0.0281 - val_accuracy: 0.9918\n",
            "Epoch 14/25\n",
            "422/422 [==============================] - 47s 112ms/step - loss: 0.0414 - accuracy: 0.9881 - val_loss: 0.0318 - val_accuracy: 0.9923\n",
            "Epoch 15/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.0421 - accuracy: 0.9878 - val_loss: 0.0313 - val_accuracy: 0.9928\n",
            "Epoch 16/25\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0418 - accuracy: 0.9881 - val_loss: 0.0370 - val_accuracy: 0.9905\n",
            "Epoch 17/25\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0408 - accuracy: 0.9882 - val_loss: 0.0245 - val_accuracy: 0.9933\n",
            "Epoch 18/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.0368 - accuracy: 0.9899 - val_loss: 0.0301 - val_accuracy: 0.9923\n",
            "Epoch 19/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.0374 - accuracy: 0.9889 - val_loss: 0.0271 - val_accuracy: 0.9928\n",
            "Epoch 20/25\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0357 - accuracy: 0.9894 - val_loss: 0.0258 - val_accuracy: 0.9932\n",
            "Epoch 21/25\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0350 - accuracy: 0.9899 - val_loss: 0.0288 - val_accuracy: 0.9925\n",
            "Epoch 22/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.0351 - accuracy: 0.9899 - val_loss: 0.0273 - val_accuracy: 0.9938\n",
            "Epoch 23/25\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0330 - accuracy: 0.9905 - val_loss: 0.0238 - val_accuracy: 0.9945\n",
            "Epoch 24/25\n",
            "422/422 [==============================] - 41s 97ms/step - loss: 0.0313 - accuracy: 0.9909 - val_loss: 0.0273 - val_accuracy: 0.9933\n",
            "Epoch 25/25\n",
            "422/422 [==============================] - 41s 98ms/step - loss: 0.0338 - accuracy: 0.9904 - val_loss: 0.0247 - val_accuracy: 0.9937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNLgt1l5x-PG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "102dd729-ed0e-4892-82e1-0e9939f09ba2"
      },
      "source": [
        "score_test = model.evaluate(x_test, y_test, verbose=0)\n",
        "score_train = model.evaluate(x_train, y_train, verbose=0)\n",
        "outputs = model.predict(x_test)\n",
        "\n",
        "for output in outputs:\n",
        "  print(np.argmax(output), end='')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Error sobre el conjunto de prueba:\", (1-score_test[1])*100)\n",
        "print(\"Error sobre el conjunto de entrenamiento:\", (1-score_train[1])*100)\n",
        "print(\"Tiempo de entrenamiento: \"+str(round(end - start,2)))\n",
        "print(\"Epoch:\", epochs)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7210414959069015973496654074013134727121174235124463556041957893746430702917329776278473613693141769605499219487397444925476790585665781016467317182029955156034465465451447232718181850892501110903164236111395294593903655722712841733887922415987230442419577282685779181803019941821297592641582920400284712402743300319652592930420711215339786561381051315561851794622506563720885411403376162192861952544283824503177579719214292049148184598837600302664933323912680566638827589618412591975408991052378940639521313657422632654897130383193446421825488400232770874479690980460635483393337808217065438096380996868578602402231975108462479329822927359180205213767125803724091867743491951739769137833672858511443107707944855408210845040617326726931462542062173410543117499484024511647194241553831456894153803251283440883317359632613607217142421796112481774807313107703552766928352256082928888749306632132293005781446029147473988471212232323917403558632676632791175649513347891169144540622315120381267162390122089902519781041795426813754418138125806211115346950922482172494403922338357358124464951069595973803713678597969637465354787807688733195273511214747545408369602744446647934558737270241165928720150917060868180337236216113790805402822984045851213174572058862541921587024436882405044793415973588053366016033441291469939844313188794887971456052221552496277221128372417176782731758262256509243397668041582918067210552022024980994654918349912281964094838602519629409606254238455038535865763396112904336957377787983072794549321402375788505148390006623784779241452499184098487707886048824766647188236300376979954336123733203384363502090746935196145450595212919940845292121736884919857511865244323568862310589296704871741097200917878472046031133967415308739693502745175808815030314037271807043198771499321790203376923377007529874426619682908311635111312302013557489696836685142445119024957183569871167632208925108145796906155838265074613473234252717264157860182577693584240883492758656086736494663241014629110639565658464391341917129354073617553301375865104234679818492862700675860937135433556302342309947284706285285730823282557646848274520389672511123678764894863831062256958141784618431280859142027090257679426244804458068985690487134580913369871057175279185249472234919217944567278819711753351376138759900288237130344589239711704965917020046707146454991795338236221111169843716450474240701988600496822384822175440439731012542101891683893628322104292437915249038536094625027466866869172599072767065247209922944233217076413874592518737155091406336049751689557938381535055386777370590255317786593895379170037238186295757862514845830627332107340393289038076547350862511004401232778525769141642435439501538919795527460111044763004306196138125627360197668929583100766216931869060006359345585304029682312115698066553862145437850935110447017016145665784472537077964285783958998628923611893407964141349314774729308084044152834952815379425625935921953069840452901031658153503559287049197755209186239621913550383376801406981299597378013046102584411546606926271794003822316057792679786884684128239403732337340620815354171575732273737854525653674171523631426743806216539193218446586977869739405464123002665708647907342188592718882760127108360536287014211444471629900188434206161222123781002166016251748214383994834727570433267600677055810702815088032772647555292846865008761711274007763864209405782747113662919483695962467706694835349005250711107679664143112241087634006330717113109975414895351982339901029393362498374047849899759282202238468482467933943144705960444461233645968565864186528455477078223701807198755917549122166711407424064769534650188283578085711013785071101145276230285969721364182405102264439616579202601435288088909676393477749064842728100783331376131665747595849916501320348220251514889121351094483259766200058215238518204996233564809283675729491286070911675991959250410890898942579898099689959851033521650281562302264355172169199551622867146040332236898538545205632839957946713736609019928801697534749943631176918411994368160413774951001162198403649071657525185470670258104571851800607318397008959832729721137531982228857389886823975629288168879180172075190209862393802111142977511219991020211464154977156222806961977148534349750748815395976903639822128685539492515144144359122330290095609328419972799595118351953549593190975492010514933615252209266012030255795508950325408845884548549221268870366438872200939919866426928545799921834078393465623926006128798204775056467430750742089942467876941373088769392292183296840128452781130357031936317730848265297390996429721167475908214457613259936114697215146381103168490730290666367728608302983253980019513960141712379749939282718091017796999216135719764576699636298122552372101045282835178112978405078847785849813803174551657493547120816073473960864877938697234021835572467283087840844585663093768934958912886813790114708174571211396212807669370528054384662795132436194476541992780136134111560707232522949812161278000822922799275134941856283128499370772324039984106096861198923559421943960406012347890123478901234567898347863409719384730914546206211117247529458429700751176668227740242189610596980308396301234567012345678901234567854874773988315827421545586444187551891363322699655338165681976837470900379302010104010479626229901234567890123456789012345678980566080237947191714004175713331697430252608943548159064363381475722001779598968823612989526248465015678901234567890123456789742090158802784461045394205013291601180477636073542418356706712581938287671462930123456701234501289140950807711293672381298871711034264742749106855535974859693038918160012345678901234567890123456789353293214552321397212891887810077875061574612507990384481865900037164266045413863995937856476220940123456789012356012345687132807599609413212383265682748180539419219679046173872965839057161093344062542346002014567890123456780123456789871375280759909115886321832656741053192196046173872965835716109625423446002012343678901234567890128456789865068941953048914055215407601706899179860817713231420078464938472563696322469025513397872257982131301234567890123456789012345678912653070414367231212960130275762919060602061584301544857578348852971381075969477993443862012345678901234567890123456789083955268491712359691112956812077582989046713456036870427475434281512025643000335706488634699827710123456789012345678012345678217250802788360276612887747737454338411974373302556635259984106096885611989235594219392060400123478901237890123478973031876402683281207104458062315185940758838926253173919960392814352925895012456012345671234510456634428101497233920933915237784024024780706932867575108167297958626281750113849186890123456789012347898178998984177337666190176321713917684143696144724401234567890123456901234781351772148344397412359160100287114047368037406926586904061920951376930220123456789012345678901234567892172508027883060276612887747737454338454119743733025563152599841060968856119892355942194913920604060123456789012345678901234567893807107556901008343150095349376924572649494122581329438221286516721393875707488506637699484106601234567890123456789012345678974040179514289437824433699586706826393286174889033905294103758778297126425236650028161043161901456789123456701234567898400724386632633014780319019127013829276559982913234319093687010582770123456789012345678901234567891748156572863386540917291513223064376904814061269223551077962947023400888513749889098902656747541353123456123460124567817241414968453784335670616870150850158423976919067123924553753182230294970274992598386700123456789012345678901234567890072655378666643883019054191270138292742655991157682943190936870105827701234567890123458901234567892121399853707757994703415814841866460553357259692621208383087495097004609162768352183861021401234567890123456789012345678976476234878698322848565020112968210652975393718381955011982604503186759930314404901235678012356789012356789970901588093278461049420501693291601187763607241706712581828768716293012345678901234567890123456789895703168415642781343472050192323557849971190783486380962101062389072345528546667918215347940001234567890123456789012345690131512492468011926687429702103601234567890123456789012345678986597023438515230121326530727464059989531747654006620637744392896095388714048523901915174862168801234789012346789012347891453309543084670771691362382389588717110342647427429279210653485969063081600123456701234789012347251643990971643620986570017432413764777984382835805471317962091733916439821864155650123456789012345678901234567896970234385130121320726405998953174700666374289871904852390191517612168012345678901234567801235678104566344281064972920933915231673784024024780706932486057510816729795652628175573501138494518689012345678901234567890123456789353293214552321397212891887810067787506157461250799034484186590003716460454138639959378564762209401234567890123456789012345678964264755472939382095601065353800341530830627817138542097674162671980694996237192253780123478901234789017898926135482643459203949738744985826623132731901135078151460049166907611012342234562012786397193961724457001668277242161069839630123456789012345678901234567891689901244374440387582175385251162138642625502806817919267668749213305580379702791780353601234567890123456789012347896426478929393001042635303415308306178092671969499671253780124567890134567801347897551997100597172236832006175862948871087758534611550723641241542048619025693636012345678901234567890123567810957518690419384470192878259606553339811061006211327788784602070368715993724943622532559417201234567890123456789012345678910127534400696657234491407957231440996183373988477621987887223933550795651411282615012345678901234567890123456788060023794717171400175713331697130260894354815906638147520017876882361295201234567890123456789012346678974614099378475853220586038103047492957171665628764995374304661132100123478901234567801234789083955268417123569111212077582986734687042775434281510233570686399827710178901234567801234789786419384470192878260653339140610062117784607036871524943641726501234567890123456\n",
            "Error sobre el conjunto de prueba: 0.55999755859375\n",
            "Error sobre el conjunto de entrenamiento: 0.2200007438659668\n",
            "Tiempo de entrenamiento: 1042.01\n",
            "Epoch: 25\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}