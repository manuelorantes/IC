{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolucionRelu_128.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY0p33JKroTh"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EElLKgKgxrb9",
        "outputId": "a992728f-ff12-4ec8-e3b0-985baaf1e848"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGhZ7NwRxw52",
        "outputId": "6852e438-7b8f-4958-8be1-8d7dd8658acb"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               204928    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 225,034\n",
            "Trainable params: 225,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpaoiV70x4_N",
        "outputId": "3f928cb4-f8b1-4cfc-b9e3-77c52e9d6038"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 25\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "start = time.time()\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "end = time.time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "422/422 [==============================] - 36s 86ms/step - loss: 0.2661 - accuracy: 0.9193 - val_loss: 0.0592 - val_accuracy: 0.9830\n",
            "Epoch 2/25\n",
            "422/422 [==============================] - 36s 86ms/step - loss: 0.0746 - accuracy: 0.9769 - val_loss: 0.0424 - val_accuracy: 0.9870\n",
            "Epoch 3/25\n",
            "422/422 [==============================] - 36s 86ms/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.0413 - val_accuracy: 0.9883\n",
            "Epoch 4/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0431 - accuracy: 0.9864 - val_loss: 0.0327 - val_accuracy: 0.9908\n",
            "Epoch 5/25\n",
            "422/422 [==============================] - 36s 86ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 0.0304 - val_accuracy: 0.9912\n",
            "Epoch 6/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0311 - accuracy: 0.9897 - val_loss: 0.0292 - val_accuracy: 0.9908\n",
            "Epoch 7/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.0269 - val_accuracy: 0.9920\n",
            "Epoch 8/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0346 - val_accuracy: 0.9922\n",
            "Epoch 9/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.0281 - val_accuracy: 0.9928\n",
            "Epoch 10/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.0315 - val_accuracy: 0.9920\n",
            "Epoch 11/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.0371 - val_accuracy: 0.9905\n",
            "Epoch 12/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 0.0292 - val_accuracy: 0.9930\n",
            "Epoch 13/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0251 - val_accuracy: 0.9932\n",
            "Epoch 14/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0283 - val_accuracy: 0.9933\n",
            "Epoch 15/25\n",
            "422/422 [==============================] - 36s 84ms/step - loss: 0.0116 - accuracy: 0.9957 - val_loss: 0.0351 - val_accuracy: 0.9915\n",
            "Epoch 16/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0284 - val_accuracy: 0.9935\n",
            "Epoch 17/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0287 - val_accuracy: 0.9932\n",
            "Epoch 18/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0305 - val_accuracy: 0.9932\n",
            "Epoch 19/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0331 - val_accuracy: 0.9935\n",
            "Epoch 20/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0349 - val_accuracy: 0.9915\n",
            "Epoch 21/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0348 - val_accuracy: 0.9922\n",
            "Epoch 22/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0373 - val_accuracy: 0.9925\n",
            "Epoch 23/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0337 - val_accuracy: 0.9943\n",
            "Epoch 24/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0341 - val_accuracy: 0.9937\n",
            "Epoch 25/25\n",
            "422/422 [==============================] - 36s 85ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0349 - val_accuracy: 0.9930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNLgt1l5x-PG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86ce533-5658-4412-a6a2-4fb9ee60da58"
      },
      "source": [
        "score_test = model.evaluate(x_test, y_test, verbose=0)\n",
        "score_train = model.evaluate(x_train, y_train, verbose=0)\n",
        "outputs = model.predict(x_test)\n",
        "\n",
        "for output in outputs:\n",
        "  print(np.argmax(output), end='')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Error sobre el conjunto de prueba:\", (1-score_test[1])*100)\n",
        "print(\"Error sobre el conjunto de entrenamiento:\", (1-score_train[1])*100)\n",
        "print(\"Tiempo de entrenamiento: \"+str(round(end - start,2)))\n",
        "print(\"Epoch:\", epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7210414959069015973496654074013134727121174235124463556041957893746430702917329776278473613693141769605499219487397444925476790585665781016467317182029955156034465465451447232718181850892501110903164236111395294593903655722712841733887922415987230442419577282685779181803019941821297592641582920400284712402743300319652592930420711215339786561381051315561851794622506563720885411403376162192861952544283824503177579719214292049148184598837600302064933323912680566638827589618412591975408991052378940639521313657422632654897130383193446421825488400232770874479690980460635483393337802217065438096380996868578602402231975108462679329822927359180205213767125803714091867743491931739769137833672858511443107707944855408210845040617326726931462542062173410543117499484024511647194241553831456894153803251283440883317359632613607217142421796112481774807313107703552766928352256082928888747306632132293005781446029147473988471212232323917403558632676632791175649513347871169144540622315120381267162390122089902519781041795426813754418138125806211115346950922482172494403922338357358124464951069595973803713678597969637465354787807688733195273511214747545408369602744446647934558737270241166928720150917060868180337236216113790805402822984045851213174572098862541921581024436882405044793415973588053366016037441291469939844313108794887971456052221552496277221128372417176722731758262256509243397668041382918067210552022024980994654918349912281964094838602519629409606254238455038535865763396112904336957377787983072794549321402375788501147390006623784779241452499184098487707886048824766647188236300376979954336123733203384363502090746935196145450595212919940845292121736884919857511865244323568862310589296704871741057200917878472046031133967415308739693502745175808815030314037271807043198771499321790203376923377007529874426619682908311635111312302013557489696836685142445119024957183569871167632208925108145796906155838265074613473234252717264157860182577693584240883492758656086736494663241014629110639565658464391341917129354073617553301375865104234679818492862700675860939135433556302342309947284706285285730823282557646848274520394672511123678764894863831062256958141784618431280859242027090257629426244804458068985690487134580913369871057175279185249472234919217944167278819711753351376138759900288237130344389239711704965917020046707146454991795338236221111169843716430474240701988600496822384822175440439731012592101891683893628322104292437915249038536094625027466866869172599072767065247209922944233217076413874592518737155091406336049751689557938381535055386777370590255317786593895379170037238186295757862514845830627332107340393289038076547390862511004401232778525769141642435439501538919795527460111044763004306146138125627360197668929583100766216931869060006359345585304029682312115698066553862145437850935110447017016145665784472537077964285783958998628923611893407964141349314774729308084044152834952815379425635935921953069840452901031658153303559287049197755209186239621913550383376601406981299597378013046102584411546606926271794003822316057792679786884684128739403732337340620815354171575732273737854525653674171523631426743806216539193218446586977869239405464123002665708647907342188592718882760127108360536287014211444471629900188434206161222123781002166016251748214383994834727570433267600677055810702815088032772647555292846865008761711274007763864209405782747113662919483695962467706694835349005250711107679664143112241087634006330717113109975414895351982339901029393362498374047849899759282202238468482467933943144705960444461233645968565864186528455477078223701807198755917549122166711407424064769534650188283578085711013785071101145276230285969721364182405102264439616579202601435288088909676393477749064842728100783331376131665747595849916501370348220251816889121351094483259766200058815238518204996233564809283675729491286070911075991959250410840898942579898099689959851033521650283562302264355172169199551622867146040332236898538545205632839957946713736609019928801697534749943631176918411994368160413774951001162198403649071657525185470670258104571851900607318397008959832729721137531982228857389886823975629288168879180172075190209862373802111142977511219991020211464154977156222806961977148534347750748815395976903639822128685539492515144144359122330290095609328419972799595118351953549593190975492010514933615252209266012030255795508950325908845884548549221268870366438872200939919866426928545799921834078393465622926006128798204775056467430750742089942467826941373087769392292183296840128452781130357031935317730848265297390996429721167475928214457613259936114697215146381103168490730290666367728608302983253880019513960141712379749939282718091017796999216135719764576699636298122552372101045282835178112978405078847785849813803174551657493547120816073473960864877938697234021835572467283087840844585663093768934958912886813790114708174571211396212807669370528054384662795132436194476541992780136134111560707232522949812161274000822922799275134941856283128499370772324039984106096861198923559421943960406012347890123478901234567898347863409719384730914546206211117247529458429700751176668227740242189610596980308396301234567012345678901234567854874773988315827421545586494187551891363322699655338165681976837470900379302010104010479626229901234567890123456789012345678980566080237947191714004175713331697430252608943548159064363381475722001779598968823612989526248465015678901234567890123456789742090158802784461045394205013291601180477636073542418356706712581938287671462930123456701234501289140950807711293672381298871711034264742749106855535974859693038918160012345678901234567890123456789353293214552321397212891887810077875061574612507990384481865900037164266045413863995937856476220940123456789012356012345687132807599609413212383265682748180539419219679046173872965839057161093344062542346002014567890123456780123456789871375280759909115886321832656741053192196046173872965835716109625423446002012343678901234567890123456789865068941953048914055215407601706899179860817713231420078464938472563696322469025513397872257982131301234567890123456789012345678912653070414367231212960130275762919060602061584301544857578348852971381075969477993443862012345678901234567890123456789083955268491712359691112956812077582989046713456036870427475434281512025643000335706488634699827710123456789012345678012345678217250802788360276612887747737454338411974373302556635259984106096885611989235594219392060400123478901237890123478973031876402683281207104458062315185940758838926253173919960392814352925895012456012345671234510456634428106497233920933715231784024024780706932867575108167297958626281750113249186890123456789012347898178998984177337666190176321713917684143696144724401234567890123456901234781351772148344397412359160100287114047368037406926586904061920951376930220123456789012345678901234567892172508027883060276612887747737454338454119743733025563152599841060968856119892355942194913920604060123456789012345678901234567893807107556901008343150095349376924572649494122581329438221286516721393875707488506637699484106601234567890123456789012345678974040179514289437824433699586706826393286174889033905294103758778297126425236650028161043161901456789123456701234567898400724386632633614780319019127013829276559982913234319093687010582770123456789012345678901234567891748156572863386540917291513223064376904814061269223551077962947023400888513749889098902656747541353123456123460124567817241414968453784335670616870150850158423976919067123924553753182230294970274992598386700123456789012345678901234567890072655378666643883019054191270138292742655991157682943190936870105827701234567890123458901234567892121399853707757994703415814841866460553357259692621208383087495097004609162768352183861021401234567890123456789012345678976476234878698322848565020112968210652975393718381955011982604503186759930314404901235678012356789012356789970901588093278461049420501693291601187763607241706712581828768716293012345678901234567890123456789895703168415642781343472050192323557849971190783486380962101062389072345528546667918215347940001234567890123456789012345690131512492468011926687429702103601234567890123456789012345678986597023438515230121326530727464059989531747654006620637744392896095388714048523901915174862168801234789012346789012347891453309543084670771691362382389588717110342647427429279210653485969063081600123456701234789012347251643990971643620986570017432413764777984382835805471317962091733916439821864155650123456789012345678901234567896970234385130121320726405998953174700666374289871404852390191517612168012345678901234567801235678104566344281064972920933915231673784024024780706932486057510816729795652628175573501138494518689012345678901234567890123456789353293214552321397212891887810067787506157461250799034484186590003716460454138639959378564762209401234567890123456789012345678964264755472939382095601065353800341530830627817138542097674162671980694996237192253780123478901234789017898926135482643459203949738744985826623132731901135078151460049166907611012347234562012786397193961724457001668277242161069839630123456789012345678901234567891689901244374440387582175385251162138642625502806817919267668749213305580379702791780353601234567890123456789012347896426478929393001042635303415308306178092671969499671253780124567890134567801347897551997100597172236832006175862948871087758534611550723641241542048619025693636012345678901234567890123567810957518690419384470192878259606553339811061006211327788784602070368715993724943622532559417201234567890123456789012345678910127534400696657234491407957231440996183373988477621987887223933550745651411282615012345678901234567890123456788060023774717171400175713331697130260894354815906238147520017876882361295201234567890123456789012346678974614099378475853220586038103047492957171665628764995374304661132100123478901234567801234789083955268417123569111212077582986734687042775434281510233570686399827710178901234567801234789786419384470192878260653339140610062117784607036871524943641726501234567890123456\n",
            "Error sobre el conjunto de prueba: 0.7300019264221191\n",
            "Error sobre el conjunto de entrenamiento: 0.10833144187927246\n",
            "Tiempo de entrenamiento: 899.2\n",
            "Epoch: 25\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}